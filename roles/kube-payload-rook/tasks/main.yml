---
- name: Create payloads config base dir
  file:
    path: '{{ kube_payload_basedir }}'
    state: directory
    owner: '{{ kube_payload_owner }}'
    group: '{{ kube_payload_group }}'
    mode: 0755

- name: Create rook payload config base dir
  file:
    path: '{{ kube_payload_basedir }}/rook'
    state: directory
    owner: '{{ kube_payload_owner }}'
    group: '{{ kube_payload_group }}'
    mode: 0755

- name: Write pv manifest (StorageClass + 3 PersistentVolume), not namespaced
  template:
    src: '001_pv_yaml.j2'
    dest: '{{ kube_payload_basedir }}/rook/pv.yaml'
    owner: '{{ kube_payload_owner }}'
    group: '{{ kube_payload_group }}'
    mode: 0644

- name: Write namespace manifest
  template:
    src: '002_namespace_yaml.j2'
    dest: '{{ kube_payload_basedir }}/rook/namespace.yaml'
    owner: '{{ kube_payload_owner }}'
    group: '{{ kube_payload_group }}'
    mode: 0644

- name: Download standard rook install manifests (only common.yaml and operator.yaml are actually used)
  get_url:
    url: 'https://raw.githubusercontent.com/rook/rook/release-{{ kube_payload_rook_release_train }}/cluster/examples/kubernetes/ceph/{{ item }}'
    dest: '{{ kube_payload_basedir }}/rook/{{ item }}'
    owner: '{{ kube_payload_owner }}'
    group: '{{ kube_payload_group }}'
    mode: 0644
  with_items:
    - 'common.yaml'
    - 'operator.yaml'
    - 'cluster.yaml' # only for comparison
    - 'filesystem.yaml' # only for comparison
    - 'storageclass-bucket-retain.yaml' # only for comparison
    - 'nfs.yaml' # only for comparison

- name: Write custom versions of cluster manifest
  template:
    src: '003_cluster_custom_yaml.j2'
    dest: '{{ kube_payload_basedir }}/rook/cluster_custom.yaml'
    owner: '{{ kube_payload_owner }}'
    group: '{{ kube_payload_group }}'
    mode: 0644

- name: Apply pv manifest (not namespaced), creates StorageClass and PersistenVolume on each node
  include_role:
    name: kube-kubectl-apply
  vars:
    kube_kubectl_apply_dir: '{{ kube_payload_basedir }}/rook'
    kube_kubectl_apply_yaml: pv.yaml

- name: Apply namespace manifest
  include_role:
    name: kube-kubectl-apply
  vars:
    kube_kubectl_apply_dir: '{{ kube_payload_basedir }}/rook'
    kube_kubectl_apply_yaml: namespace.yaml

- name: Apply rook common manifest
  include_role:
    name: kube-kubectl-apply
  vars:
    kube_kubectl_apply_dir: '{{ kube_payload_basedir }}/rook'
    kube_kubectl_apply_yaml: common.yaml

- name: Apply rook operator manifest
  include_role:
    name: kube-kubectl-apply
  vars:
    kube_kubectl_apply_dir: '{{ kube_payload_basedir }}/rook'
    kube_kubectl_apply_yaml: operator.yaml

- name: Wait for controller pod to be created
  shell: "/usr/local/bin/kubectl get pod --namespace=rook-ceph --selector='app=rook-ceph-operator' --output=jsonpath='{.items[*].metadata.labels.app}' | grep rook-ceph-operator"
  register: rook_controller_pods_created
  failed_when: rook_controller_pods_created.rc == 2
  until: rook_controller_pods_created.rc == 0
  run_once: true
  retries: 10
  delay: 30
  changed_when: false

- name: Wait for controller pod to become ready
  shell: "/usr/local/bin/kubectl wait --namespace=rook-ceph --for=condition=Ready pods --selector='app=rook-ceph-operator' --timeout=600s"
  register: rook_controller_pods_ready
  run_once: true
  changed_when: false

- name: Apply rook cluster manifest
  include_role:
    name: kube-kubectl-apply
  vars:
    kube_kubectl_apply_dir: '{{ kube_payload_basedir }}/rook'
    kube_kubectl_apply_yaml: cluster_custom.yaml

- name: Wait for 3 osd pods to be created
  shell: "/usr/local/bin/kubectl get pod --namespace=rook-ceph --selector='app=rook-ceph-osd' --output=jsonpath='{range .items[*]}{.metadata.labels.app}{\"\\n\"}{end}' | wc -l | grep 3"
  register: rook_controller_pods_created
  failed_when: rook_controller_pods_created.rc == 2
  until: rook_controller_pods_created.rc == 0
  run_once: true
  retries: 10
  delay: 30
  changed_when: false

- name: Wait for all osd pods to become ready
  shell: "/usr/local/bin/kubectl wait --namespace=rook-ceph --for=condition=Ready pods --selector='app=rook-ceph-osd' --timeout=600s"
  register: rook_controller_pods_ready
  run_once: true
  changed_when: false

